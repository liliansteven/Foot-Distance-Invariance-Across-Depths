# Foot-Distance-Estimation-Across-Depths

## Overview
This project is designed to measure the distance between a person's feet consistently across different depths (both close to and far from the camera). By integrating depth estimation, pose detection, and distance calculation methods, the pipeline ensures accurate and reliable measurements.

---

### Repository Structure
```
Foot-Distance-Invariance-Across-Depths/
├── README.md
├── requirements.txt
├── notebooks/
│   ├── Foot_Distance_using_several_Depth_Estimation_methods_with_pose_detection.ipynb
├── src/
│   ├── depth_estimation.py
│   ├── pose_estimation.py
│   ├── distance_calculation.py
│   ├── utils.py
│   ├── main.py
├── assets/
│   ├── example_videos/
│   │   ├── input_video.mp4
│   ├── checkpoints/
│   │   ├── depth_anything_v2_vits.pth
├── results/
│   ├── output_with_distances.mp4
```

#### Explanation of Each Component
1. **`requirements.txt`**:
   - Lists all dependencies required to run the project.

2. **`notebooks/`**:
   - Contains interactive Jupyter notebooks for experimentation and demonstration.
   - **`Foot_Distance_using_several_Depth_Estimation_methods_with_pose_detection.ipynb`**: The primary notebook showcasing the full pipeline with explanations.

3. **`src/`**:
   - Modular Python scripts for each component of the pipeline:
     - **`depth_estimation.py`**: Implements depth estimation models (`DepthPro`, `DepthAnything`, etc.).
     - **`pose_estimation.py`**: Implements pose detection using MediaPipe.
     - **`distance_calculation.py`**: Implements distance calculation methods (2D, 3D without focal, real-world with focal).
     - **`utils.py`**: Utility functions for loading models, preprocessing, and postprocessing.
     - **`main.py`**: The entry point for running the pipeline from the command line.

4. **`assets/`**:
   - Stores input data and pre-trained model checkpoints:
     - **`example_videos/`**: Example videos for testing the pipeline.
     - **`checkpoints/`**: Pre-trained model weights (e.g., `depth_anything_v2_vits.pth`).

5. **`results/`**:
   - Stores output files generated by the pipeline, such as annotated videos (`output_with_distances.mp4`).

---

## Usage

### Setting Up the Environment
To prepare the virtual environment, follow these steps:
```bash
conda -m venv footdistancevenv
conda activate footdistancevenv
!git clone https://github.com/DepthAnything/Depth-Anything-V2
%cd Depth-Anything-V2  # or cd Depth-Anything-V2 on terminal 
!pip install -r requirements.txt
!pip install mediapipe
!pip install git+https://github.com/huggingface/transformers.git
!pip install mediapipe
```

### Running the Pipeline
1. **Using the Notebook**:
   - Open `notebooks/Foot_Distance_using_several_Depth_Estimation_methods_with_pose_detection.ipynb` in Google Colab or Jupyter Notebook.

2. **Using the Script**:
   - Run the following command in your terminal:
     ```bash
     python src/main.py --video_path assets/example_videos/input_video.mp4 --depth_model depthpro
     ```
---

### Notebook Structure: `Foot_Distance_using_several_Depth_Estimation_methods_with_pose_detection.ipynb`
The notebook is organized into the following sections:
1. **Depth Estimation**:
   - Implementation and comparison of depth estimation models (`DepthPro`, `DepthAnything`, `ZoeDepth`, `iMADS`).
2. **Pose Detection**:
   - Key concept: Using MediaPipe Pose to detect keypoints such as feet and shoulders.
3. **Distance Calculation**:
   - Three methods for calculating foot distances:
     - 2D Euclidean Distance
     - 3D Euclidean Distance (No Focal Length)
     - Real-World 3D Distance
4. **Results and Visualization**:
   - saved annotated video frames with calculated distances.

---

### Pipeline Description
1. **Input Video**:
   - A video file where a person stands in front of the camera, walks backward, and stands again with varying foot positions.

2. **Depth Estimation**:
   - Four depth estimation models are implemented:
     - **DepthPro**: High-quality depth maps with optional focal length estimation.
     - **DepthAnything**: Lightweight and versatile but requires manual focal length estimation.
     - **ZoeDepth**: Accurate depth estimation suitable for both indoor and outdoor scenarios.
     - **iMADS (DPT-Hybrid-MiDaS)**: Efficient and widely used for real-time applications.

3. **Pose Detection**:
   - MediaPipe Pose is used to detect keypoints such as feet, shoulders, and other body landmarks.

4. **Distance Calculation**:
   - Three approaches to calculate the foot distance:
     - **2D Euclidean Distance**: Simple pixel-based distance without depth.
     - **3D Euclidean Distance (No Focal Length)**: Incorporates depth but ignores camera intrinsics.
     - **Real-World 3D Distance**: Uses depth, focal length, and camera intrinsics for accurate real-world measurements.

5. **Focal Length Estimation**:
   - For models that do not provide focal length (e.g., DepthAnything, ZoeDepth, iMADS), the focal length is estimated dynamically using shoulder keypoints and depth.

6. **Output Video**:
   - An annotated video displaying all three distances (2D, 3D without focal, and real-world) for comparison.
